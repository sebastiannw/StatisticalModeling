pscores <- predict(pscorereg, type = "response")
#use type="response" since we want probabilities
head(pscores)
summary(pscores)
ggplot(MinWage, aes(pscores)) +
geom_histogram(alpha=.6,fill=rainbow(10),bins=10)
#we don't have probabilities that are either too close to 0 or 1 which is good.
#look at distribution of propensity scores for treateds and controls
MinWage$state <- "NJ"
MinWage$state[MinWage$PA.NJ == 1] <- "PA"
ggplot(MinWage, aes(y=pscores, x=state, fill=state)) +
geom_boxplot()
#we can see clear differences in the distributions of propensity scores
#thus, a simple comparison of the outcomes would be confounded
#by differences in the background variables
#actually we need to overlay the distributions to see overlap clearly
ggplot(MinWage, aes(x=pscores, fill=state)) +
geom_density(alpha=.3) +
xlim(0, 1)
###########################################################################
###########################################################################
########################## Minimum wage analysis ##########################
###########################################################################
###########################################################################
###### Clear environment and load libraries
rm(list = ls())
library(MatchIt) #for propensity score matching
library(cobalt)
library(ggplot2)
###### Load the data
MinWage <- read.csv("MinimumWageData.csv",header=T,
colClasses=c("factor","numeric","numeric","numeric",
"factor","factor","factor","factor"))
###### View properties of the data
str(MinWage)
head(MinWage)
dim(MinWage)
summary(MinWage)
#note that there are more in NJ than PA, and we labeled NJ = 1 and PA = 0
#we will want to switch the 0s and 1s later for matching
###### Covariate balance
#first, let's summarize the predictors by NJ and by PA.
summary(MinWage[MinWage$NJ.PA == 0, 3:8]) #first PA
summary(MinWage[MinWage$NJ.PA == 1, 3:8]) #now NJ
bal.tab(list(treat=MinWage$NJ.PA,covs=MinWage[,3:8],estimand="ATE"))
love.plot(list(treat=MinWage$NJ.PA,covs=MinWage[,3:8],estimand="ATE"),stars = "std")
#the distributions of prior employment are not well balanced
#other variables pretty close, but we might be able to do better by matching
#since there are more in PA than NJ, let's make PA the treated and NJ the control
#we can do this pretty easily by making a new dummy variable
MinWage$PA.NJ = 0
MinWage$PA.NJ[MinWage$NJ.PA == 0] = 1
###### Propensity scores estimation
pscorereg <- glm(PA.NJ ~ EmploymentPre + WagePre + BurgerKing + KFC + Roys + Wendys, data = MinWage)
summary(pscorereg)
#oops... we didn't need to include one of the dummy variables for the restaurants
#all four dummy variables sum up to the intercept, so that's a problem
#just like we usually have to make one level of all factor variables the baseline
#drop Wendys
pscorereg <- glm(PA.NJ ~ EmploymentPre + WagePre + BurgerKing + KFC + Roys, data = MinWage)
summary(pscorereg)
#EmploymentPre seems to be the only significant variable
#Not really a problem since we care about using the model to predict
#now let's estimate the propensity scores
pscores <- predict(pscorereg, type = "response")
#use type="response" since we want probabilities
head(pscores)
summary(pscores)
ggplot(MinWage, aes(pscores)) +
geom_histogram(alpha=.6,fill=rainbow(10),bins=10)
#we don't have probabilities that are either too close to 0 or 1 which is good.
#look at distribution of propensity scores for treateds and controls
MinWage$state <- "NJ"
MinWage$state[MinWage$PA.NJ == 1] <- "PA"
ggplot(MinWage, aes(y=pscores, x=state, fill=state)) +
geom_boxplot()
#we can see clear differences in the distributions of propensity scores
#thus, a simple comparison of the outcomes would be confounded
#by differences in the background variables
#actually we need to overlay the distributions to see overlap clearly
ggplot(MinWage, aes(x=pscores, fill=state)) +
geom_density(alpha=.3) +
xlim(0, 1)
###########################################################################
###########################################################################
########################## Minimum wage analysis ##########################
###########################################################################
###########################################################################
###### Clear environment and load libraries
rm(list = ls())
library(MatchIt) #for propensity score matching
library(cobalt)
library(ggplot2)
###### Load the data
MinWage <- read.csv("MinimumWageData.csv",header=T,
colClasses=c("factor","numeric","numeric","numeric",
"factor","factor","factor","factor"))
###### View properties of the data
str(MinWage)
head(MinWage)
dim(MinWage)
summary(MinWage)
#note that there are more in NJ than PA, and we labeled NJ = 1 and PA = 0
#we will want to switch the 0s and 1s later for matching
###### Covariate balance
#first, let's summarize the predictors by NJ and by PA.
summary(MinWage[MinWage$NJ.PA == 0, 3:8]) #first PA
summary(MinWage[MinWage$NJ.PA == 1, 3:8]) #now NJ
bal.tab(list(treat=MinWage$NJ.PA,covs=MinWage[,3:8],estimand="ATE"))
love.plot(list(treat=MinWage$NJ.PA,covs=MinWage[,3:8],estimand="ATE"),stars = "std")
#the distributions of prior employment are not well balanced
#other variables pretty close, but we might be able to do better by matching
#since there are more in PA than NJ, let's make PA the treated and NJ the control
#we can do this pretty easily by making a new dummy variable
MinWage$PA.NJ = 0
MinWage$PA.NJ[MinWage$NJ.PA == 0] = 1
###### Propensity scores estimation
pscorereg <- glm(PA.NJ ~ EmploymentPre + WagePre + BurgerKing + KFC + Roys + Wendys, data = MinWage)
summary(pscorereg)
#oops... we didn't need to include one of the dummy variables for the restaurants
#all four dummy variables sum up to the intercept, so that's a problem
#just like we usually have to make one level of all factor variables the baseline
#drop Wendys
pscorereg <- glm(PA.NJ ~ EmploymentPre + WagePre + BurgerKing + KFC + Roys, data = MinWage)
summary(pscorereg)
#EmploymentPre seems to be the only significant variable
#Not really a problem since we care about using the model to predict
#now let's estimate the propensity scores
pscores <- predict(pscorereg, type = "response")
#use type="response" since we want probabilities
head(pscores)
summary(pscores)
ggplot(MinWage, aes(pscores)) +
geom_histogram(alpha=.6,fill=rainbow(10),bins=10)
#we don't have probabilities that are either too close to 0 or 1 which is good.
#look at distribution of propensity scores for treateds and controls
MinWage$state <- "NJ"
MinWage$state[MinWage$PA.NJ == 1] <- "PA"
ggplot(MinWage, aes(y=pscores, x=state, fill=state)) +
geom_boxplot()
#we can see clear differences in the distributions of propensity scores
#thus, a simple comparison of the outcomes would be confounded
#by differences in the background variables
#actually we need to overlay the distributions to see overlap clearly
ggplot(MinWage, aes(x=pscores, fill=state)) +
geom_density(alpha=.3) +
xlim(0, 1)
MinWage <- read.csv("MinimumWageData.csv",header=T,
colClasses=c("factor","numeric","numeric","numeric",
"factor","factor","factor","factor"))
MinWage <- read.csv("MinimumWageData.csv",header=T,
colClasses=c("factor","numeric","numeric","numeric",
"factor","factor","factor","factor"))
###########################################################################
###########################################################################
########################## Minimum wage analysis ##########################
###########################################################################
###########################################################################
###### Clear environment and load libraries
rm(list = ls())
library(MatchIt) #for propensity score matching
library(cobalt)
library(ggplot2)
###### Load the data
MinWage <- read.csv("MinimumWageData.csv",header=T,
colClasses=c("factor","numeric","numeric","numeric",
"factor","factor","factor","factor"))
###### View properties of the data
str(MinWage)
head(MinWage)
dim(MinWage)
summary(MinWage)
#note that there are more in NJ than PA, and we labeled NJ = 1 and PA = 0
#we will want to switch the 0s and 1s later for matching
###### Covariate balance
#first, let's summarize the predictors by NJ and by PA.
summary(MinWage[MinWage$NJ.PA == 0, 3:8]) #first PA
summary(MinWage[MinWage$NJ.PA == 1, 3:8]) #now NJ
bal.tab(list(treat=MinWage$NJ.PA,covs=MinWage[,3:8],estimand="ATE"))
love.plot(list(treat=MinWage$NJ.PA,covs=MinWage[,3:8],estimand="ATE"),stars = "std")
#the distributions of prior employment are not well balanced
#other variables pretty close, but we might be able to do better by matching
#since there are more in PA than NJ, let's make PA the treated and NJ the control
#we can do this pretty easily by making a new dummy variable
MinWage$PA.NJ = 0
MinWage$PA.NJ[MinWage$NJ.PA == 0] = 1
###### Propensity scores estimation
pscorereg <- glm(PA.NJ ~ EmploymentPre + WagePre + BurgerKing + KFC + Roys + Wendys, data = MinWage)
summary(pscorereg)
#oops... we didn't need to include one of the dummy variables for the restaurants
#all four dummy variables sum up to the intercept, so that's a problem
#just like we usually have to make one level of all factor variables the baseline
#drop Wendys
pscorereg <- glm(PA.NJ ~ EmploymentPre + WagePre + BurgerKing + KFC + Roys, data = MinWage)
summary(pscorereg)
#EmploymentPre seems to be the only significant variable
#Not really a problem since we care about using the model to predict
#now let's estimate the propensity scores
pscores <- predict(pscorereg, type = "response")
#use type="response" since we want probabilities
head(pscores)
summary(pscores)
ggplot(MinWage, aes(pscores)) +
geom_histogram(alpha=.6,fill=rainbow(10),bins=10)
#we don't have probabilities that are either too close to 0 or 1 which is good.
#look at distribution of propensity scores for treateds and controls
MinWage$state <- "NJ"
MinWage$state[MinWage$PA.NJ == 1] <- "PA"
ggplot(MinWage, aes(y=pscores, x=state, fill=state)) +
geom_boxplot()
#we can see clear differences in the distributions of propensity scores
#thus, a simple comparison of the outcomes would be confounded
#by differences in the background variables
#actually we need to overlay the distributions to see overlap clearly
ggplot(MinWage, aes(x=pscores, fill=state)) +
geom_density(alpha=.3) +
xlim(0, 1)
#the propensity scores overlap very well
#so we can feel good about prospects for matching
score_pred
setwd("~/Documents/Documentos - MacBook Pro de SebastiaÌn/IDS/1stSemester/MRD_Lab6")
knitr::opts_chunk$set(echo = TRUE)
library(arm); library(pROC); library(e1071); library(caret); library(knitr)
library(rms); library(ggplot2); library(lme4); library(rstan); library(brms)
library(sjPlot); library(dplyr); library(kableExtra); library(formatR); library(ggfortify)
library(quantreg); library(gridExtra); library(Hmisc); library(corrplot); library(GGally)
library(psych); library(car); library(huxtable); library(stargazer); library(DataExplorer)
library(GGally); library(MASS); library(data.table); library(tidyverse); library(lmerTest)
library(ggpubr); library(reshape2); library(mice); library(naniar); library(cobalt)
library(MatchIt); library(randomForest)
rb <- c('red', 'orange', 'yellow', 'green', 'blue', 'purple')
RHC <- read.table('rhc.txt', head = T)
RHC <- RHC[, -which(names(RHC) == 'surv2md1')]
bal_tab <- bal.tab(covs = RHC[,2:52], treat = as.factor(RHC$treatment), estimand = 'ATT')
kable(
bal_tab$Balance[1:33, c('Type', 'Diff.Un')],
row.names = TRUE,
label = 'tables', format = 'latex', booktabs = TRUE
) %>% kable_styling(
latex_options = 'HOLD_position'
)
kable(
bal_tab$Balance[34:77, c('Type', 'Diff.Un')],
row.names = TRUE,
label = 'tables', format = 'latex', booktabs = TRUE
) %>% kable_styling(
latex_options = 'HOLD_position'
)
love.plot(list(treat = as.factor(RHC$treatment), covs = RHC[, 2:52], estimand = 'ATT'),
stars = 'std')
r1 <- glm(
dth30 ~ treatment + age + sex + race + edu + income + ninsclas + cat1 + cat2 + resp + card +
neuro + gastr + renal +  meta +  hema + seps + trauma +  ortho + das2d3pc + dnr1 + ca + aps1 +
scoma1 + wtkilo1 + temp1 + meanbp1 + resp1 + hrt1 + pafi1 + paco21 + ph1 + wblc1 + hema1 +
sod1 + pot1 + crea1 + bili1 + alb1 + cardiohx + chfhx + dementhx + psychhx + chrpulhx +
renalhx + liverhx + gibledhx + malighx + immunhx + transhx + amihx + wt0,
data = RHC, family = binomial(link = logit)
)
test_set <- RHC[RHC$treatment == TRUE,]
p1 <- predict(r1, test_set, type = 'response')
test_set$treatment <- FALSE
p0 <- predict(r1, test_set, type = 'response')
p <- mean(p1 - p0);
kable(p,
row.names = TRUE,
label = 'tables', format = 'latex', booktabs = TRUE
) %>% kable_styling(
latex_options = 'HOLD_position'
)
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
score_pred
View(RHC)
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
sum(score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
))
sum(score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatmentC == TRUE])
))
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
#sum(score_pred < max(
#min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
#))
sum(score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatmentC == TRUE])
))
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
sum(score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
))
#sum(score_pred > min(
#max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatmentC == TRUE])
#))
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
sum(score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
))
sum(score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
))
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
sum(score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
))
sum(score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
))
index <- !(
score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
)
| score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
)
)
RHC <- RHC[index,]
#5: some of corvariates are improved after nearest neighbor matching. 10 variables (cat1, aps1, ph1, resp1,....) still shows imbalances
#sum(pscores_pred < max(min(pscores_pred[RHC$treatment==TRUE]), min(pscores_pred[RHC$treatment==FALSE])))
#sum(pscores_pred > min(max(pscores_pred[RHC$treatment==TRUE]), max(pscores_pred[RHC$treatment==FALSE])))
rhc1 <- RHC[(
score_pred >= max(
min(score_pred[RHC$treatment == TRUE]), min(score_pred[RHC$treatment == FALSE])
)
& score_pred <= min(
max(score_pred[RHC$treatment == TRUE]), max(score_pred[RHC$treatment == FALSE])
)
),]
matches <- matchit(formula(score), method = 'nearest', distance = 'logit', data = rhc1)
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
sum(score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
))
sum(score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
))
index <- !(
score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
)
| score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
)
)
RHC <- RHC[index,]
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
sum(score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
))
sum(score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
))
knitr::opts_chunk$set(echo = TRUE)
library(arm); library(pROC); library(e1071); library(caret); library(knitr)
library(rms); library(ggplot2); library(lme4); library(rstan); library(brms)
library(sjPlot); library(dplyr); library(kableExtra); library(formatR); library(ggfortify)
library(quantreg); library(gridExtra); library(Hmisc); library(corrplot); library(GGally)
library(psych); library(car); library(huxtable); library(stargazer); library(DataExplorer)
library(GGally); library(MASS); library(data.table); library(tidyverse); library(lmerTest)
library(ggpubr); library(reshape2); library(mice); library(naniar); library(cobalt)
library(MatchIt); library(randomForest)
rb <- c('red', 'orange', 'yellow', 'green', 'blue', 'purple')
RHC <- read.table('rhc.txt', head = T)
RHC <- RHC[, -which(names(RHC) == 'surv2md1')]
bal_tab <- bal.tab(covs = RHC[,2:52], treat = as.factor(RHC$treatment), estimand = 'ATT')
kable(
bal_tab$Balance[1:33, c('Type', 'Diff.Un')],
row.names = TRUE,
label = 'tables', format = 'latex', booktabs = TRUE
) %>% kable_styling(
latex_options = 'HOLD_position'
)
kable(
bal_tab$Balance[34:77, c('Type', 'Diff.Un')],
row.names = TRUE,
label = 'tables', format = 'latex', booktabs = TRUE
) %>% kable_styling(
latex_options = 'HOLD_position'
)
love.plot(list(treat = as.factor(RHC$treatment), covs = RHC[, 2:52], estimand = 'ATT'),
stars = 'std')
r1 <- glm(
dth30 ~ treatment + age + sex + race + edu + income + ninsclas + cat1 + cat2 + resp + card +
neuro + gastr + renal +  meta +  hema + seps + trauma +  ortho + das2d3pc + dnr1 + ca + aps1 +
scoma1 + wtkilo1 + temp1 + meanbp1 + resp1 + hrt1 + pafi1 + paco21 + ph1 + wblc1 + hema1 +
sod1 + pot1 + crea1 + bili1 + alb1 + cardiohx + chfhx + dementhx + psychhx + chrpulhx +
renalhx + liverhx + gibledhx + malighx + immunhx + transhx + amihx + wt0,
data = RHC, family = binomial(link = logit)
)
test_set <- RHC[RHC$treatment == TRUE,]
p1 <- predict(r1, test_set, type = 'response')
test_set$treatment <- FALSE
p0 <- predict(r1, test_set, type = 'response')
p <- mean(p1 - p0);
kable(p,
row.names = TRUE,
label = 'tables', format = 'latex', booktabs = TRUE
) %>% kable_styling(
latex_options = 'HOLD_position'
)
score <- glm(treatment ~ . - dth30, data = RHC, family = binomial(link = logit))
#summary(score)
score_pred <- predict(score, type = 'response')
ggplot(RHC, aes(x = score_pred, fill = treatment)) +
geom_density(alpha = 0.3) +
xlim(0, 1)
sum(score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
))
sum(score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
))
index <- !(
score_pred < max(
min(score_pred[RHC$treatment == FALSE]), min(score_pred[RHC$treatment == TRUE])
)
| score_pred > min(
max(score_pred[RHC$treatment == FALSE]), max(score_pred[RHC$treatment == TRUE])
)
)
RHC_2 <- RHC[index,]
#5: some of corvariates are improved after nearest neighbor matching. 10 variables (cat1, aps1, ph1, resp1,....) still shows imbalances
#sum(pscores_pred < max(min(pscores_pred[RHC$treatment==TRUE]), min(pscores_pred[RHC$treatment==FALSE])))
#sum(pscores_pred > min(max(pscores_pred[RHC$treatment==TRUE]), max(pscores_pred[RHC$treatment==FALSE])))
matches <- matchit(formula(score), method = 'nearest', distance = 'logit', data = RHC_2)
rhcmatcheddata <- match.data(matches)
bal.tab(list(
treat = as.numeric(rhcmatcheddata$treatment), covs = rhcmatcheddata[, 2:52], estimand = 'ATT'
))
love.plot(list(
treat = as.numeric(rhcmatcheddata$treatment), covs = rhcmatcheddata[, 2:52], estimand = 'ATT'
), stars = 'std')
treatpat <- mean(rhcmatcheddata$dth30[rhcmatcheddata$treatment == 1]) -
mean(rhcmatcheddata$dth30[rhcmatcheddata$treatment == 0])
se <- sqrt(
var(rhcmatcheddata$dth30[rhcmatcheddata$treatment == 1]) / 2175 +
var(rhcmatcheddata$dth30[rhcmatcheddata$treatment == 1]) / 2175
)
treatpat; treatpat - 1.96 * se; treatpat + 1.96 * se
r1 <- glm(
dth30 ~ treatment + age + sex + race + edu + income + ninsclas + cat1 + cat2 + resp + card +
neuro + gastr + renal +  meta +  hema + seps + trauma +  ortho + das2d3pc + dnr1 + ca + aps1 +
scoma1 + wtkilo1 + temp1 + meanbp1 + resp1 + hrt1 + pafi1 + paco21 + ph1 + wblc1 + hema1 +
sod1 + pot1 + crea1 + bili1 + alb1 + cardiohx + chfhx + dementhx + psychhx + chrpulhx +
renalhx + liverhx + gibledhx + malighx + immunhx + transhx + amihx + wt0,
data = RHC, family = binomial(link = logit)
)
test_set <- RHC[RHC$treatment == TRUE,]
p1 <- predict(r1, test_set, type = 'response')
test_set$treatment <- FALSE
p0 <- predict(r1, test_set, type = 'response')
p <- mean(p1 - p0);
colnames(p) <- 'ATT'
r1 <- glm(
dth30 ~ treatment + age + sex + race + edu + income + ninsclas + cat1 + cat2 + resp + card +
neuro + gastr + renal +  meta +  hema + seps + trauma +  ortho + das2d3pc + dnr1 + ca + aps1 +
scoma1 + wtkilo1 + temp1 + meanbp1 + resp1 + hrt1 + pafi1 + paco21 + ph1 + wblc1 + hema1 +
sod1 + pot1 + crea1 + bili1 + alb1 + cardiohx + chfhx + dementhx + psychhx + chrpulhx +
renalhx + liverhx + gibledhx + malighx + immunhx + transhx + amihx + wt0,
data = RHC, family = binomial(link = logit)
)
test_set <- RHC[RHC$treatment == TRUE,]
p1 <- predict(r1, test_set, type = 'response')
test_set$treatment <- FALSE
p0 <- predict(r1, test_set, type = 'response')
p <- mean(p1 - p0)
kable(p,
row.names = TRUE,
col.names = c('ATT'),
label = 'tables', format = 'latex', booktabs = TRUE
) %>% kable_styling(
latex_options = 'HOLD_position'
)
